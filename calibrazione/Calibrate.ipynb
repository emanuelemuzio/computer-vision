{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 1 - Calibrazione\n",
    "\n",
    "## Emanuele Muzio - 0766230\n",
    "\n",
    "Per questo primo assignment, viene richiesto di stimare:\n",
    "\n",
    "1. I parametri intrinseci della camera (matrice K);\n",
    "2. Posa della camera (parametri estrinseci R e t);\n",
    "3. Pixel nelle immagini acquisite corrispondenti al pavimento.\n",
    "\n",
    "Per i primi due punti è stato scelto l'algoritmo di calibrazione DLT, che consiste di 4 step e ci consente di:\n",
    "\n",
    "1.1: Trovare le corrispondenze tra i punti 2D e 3D dell'immagine;\n",
    "\n",
    "1.2: Derivare la matrice di camera P;\n",
    "\n",
    "1.3: Usare la fattorizzazione QR per derivare K e R;\n",
    "\n",
    "2.1: Trovare il vettore di traslazione _t_.\n",
    "\n",
    "Viene richiesto inoltre di fare analizzare i risultati ottenuti confrontandoli con le implementazioni già esistenti nella libreria Python per la CV _OpenCV_, usando per il DLT un set di 6, 12 e 24 punti per le stime.\n",
    "\n",
    "Dovremo infine proiettare i punti 3D sul pavimento, e testarne la bontà tramite MSE. In particolare, per testare la posa della camera, dovremo usare almeno 12 punti e usare una tecnica di **4-fold cross-validation** per misurare l'MSE medio nelle 4 pieghe/fold.  \n",
    "\n",
    "### 1.1 Corrispondenze dei punti\n",
    "\n",
    "![CUBE](cube.png)\n",
    "\n",
    "Prepariamo per prima cosa due set di punti:\n",
    "- Punti dell'oggetto, ovvero false coordinate 3D che hanno come punto di riferimento un angolo del cubo;\n",
    "- Punti dell'immagine, ovvero coordinate nell'immagine dei relativi punti 3D.\n",
    "\n",
    "Decidiamo inoltre quanti punti vogliamo usare per la calibrazione (più punti, calibrazione migliore?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlt\n",
    "\n",
    "points = 12 # 6, 12 o 24\n",
    "objp, imgp = dlt.getPoints(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizializziamo i valori ottenibili da OpenCv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENCV_ret, OPENCV_K, OPENCV_dist, OPENCV_Rs, OPENCV_ts = dlt.OPENCVCalibrateCamera(points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Matrice di camera P\n",
    "\n",
    "Fatto questo procediamo a stimare la matrice di camera P di dimensioni _3x4_ usando le corrispondenze dei punti.\n",
    "Il principio alla base di questo passaggio è quello per cui, sapendo che un punto dell'immagine è ottenuto dal prodotto tra un punto dell'oggetto e la matrice di camera, possiamo riscrivere il seguente sistema:\n",
    "\n",
    "![Screen1](./screen/1.png)\n",
    "\n",
    "In questo modo: \n",
    "\n",
    "![Screen2](./screen/2.png)\n",
    "\n",
    "Quello che abbiamo adesso è un problema nella forma $Ap = 0$. Quello che possiamo fare per la matrice di proiezione, inoltre, è un'approssimazione quanto più corretta fino a un certo grado, per cui abbiamo due opzioni:\n",
    "- Dividere per $p_3,_4$ tutti i parametri\n",
    "- Aggiungere un vincolo tale per cui $||p||^2 = 1$\n",
    "\n",
    "Nel secondo caso, dovremo trovare una p tale da avvicinarci quanto più possibile allo 0 e risolvere il problema di minimizzazione.\n",
    "\n",
    "La soluzione è quindi applicare SVD alla matrice A, per cui $A = USV^T$.\n",
    "Fatto questo, la matrice P risiederà nell'ultimo vettore di $V$ (andiamo a modificarne la forma per avere la nostra matrice normalizzata P 3x4)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "P = dlt.estimateCameraMatrix(objp, imgp, points)\n",
    "P = P/dlt.np.linalg.norm(P)\n",
    "P = P.reshape(3,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Fattorizzazione RQ\n",
    "\n",
    "Una volta trovata la matrice di proiezione, dobbiamo ricordarci che per le prime tre colonne di P, abbiamo:\n",
    "\n",
    "![Screen3](./screen/3.png)\n",
    "\n",
    "Ovvero cioè una matrice triangolare superiore per una matrice ortogonale, quindi una fattorizzazione RQ.\n",
    "Una volta trovata quindi la matrice K (tramite fattorizzazione RQ troviamo R (=K) e Q (=R))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "K, R = dlt.getKR(P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Vettore di traslazione\n",
    "\n",
    "Possiamo procedere a calcolare $t = K^{-1}P_4$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = dlt.getT(K, P)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Punti del pavimento\n",
    "\n",
    "Procediamo adesso a trovare i punti del pavimento della nostra immagine.\n",
    "\n",
    "Normalizziamo in primo luogo K affinchè in posizione K$_3_3$ ci sia 1.\n",
    "\n",
    "Analizziamo la differenza tra la matrice K calcolata da noi e quella calcolata da OpenCV:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K \n",
      "\n",
      " [[-1.1291652e+03  3.9733681e+01  1.4317920e+02]\n",
      " [-0.0000000e+00  1.0422750e+03 -3.3560303e+02]\n",
      " [-0.0000000e+00 -0.0000000e+00  1.0000000e+00]] \n",
      "\n",
      " K OpenCV \n",
      "\n",
      " [[ 1.07050242e+03  0.00000000e+00  6.62627768e+01]\n",
      " [ 0.00000000e+00  9.97867856e+02 -3.44741388e+02]\n",
      " [ 0.00000000e+00  0.00000000e+00  1.00000000e+00]] \n",
      "\n",
      " Errore assoluto \n",
      "\n",
      " [[2199.66757814   39.73368073   76.91642244]\n",
      " [   0.           44.40716877    9.13836028]\n",
      " [   0.            0.            0.        ]]\n"
     ]
    }
   ],
   "source": [
    "K = K/K[2,2]\n",
    "\n",
    "print(\n",
    "    'K', '\\n\\n', K, '\\n\\n', # Matrice calcolata ,\n",
    "    'K OpenCV', '\\n\\n', OPENCV_K, '\\n\\n', # Matrice calcolata da OpenCV\n",
    "    'Errore assoluto', '\\n\\n', abs(K - OPENCV_K), \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All'aumentare dei punti utilizzati per i calcoli abbiamo una diminuzione visibile dell'errore.\n",
    "\n",
    "Procediamo infine a proiettare i punti al suolo e all'analisi delle differenze, trasformando per prima cosa la matrice di rotazione R in un vettore di rotazione grazie alla funzione presente nella libreria di OpenCV _Rodrigues(R)_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average MSE: \n",
      "\n",
      " 218.85333333333335\n"
     ]
    }
   ],
   "source": [
    "rodr = dlt.cv.Rodrigues(R)\n",
    "\n",
    "OPENCV_ground = dlt.getGround(OPENCV_Rs[0], OPENCV_ts[0], OPENCV_K, OPENCV_dist)\n",
    "ground = dlt.getGround(rodr[0], t, K, None)\n",
    "\n",
    "dlt.drawGround(OPENCV_ground, 'OpenCV Ground')\n",
    "dlt.drawGround(ground, 'My Ground')\n",
    "\n",
    "averageMse = dlt.KFoldCrossVal(ground, OPENCV_ground, 4)\n",
    "\n",
    "print('Average MSE: \\n\\n', averageMse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sperimentalmente, notiamo una variazione notevole dell'MSE medio al variare dei punti N presi in considerazione:\n",
    "\n",
    "| N  | Average MSE |\n",
    "|----|-------------|\n",
    "| 6  | 165274.68   |\n",
    "| 12 | 218.85      |\n",
    "| 24 | 29.15       |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Riferimenti\n",
    "\n",
    "- W. Burger, 2016, Zhang’s Camera Calibration Algorithm: In-Depth Tutorial and Implementation. _Technical Report HGB16-05_.\n",
    "- Slide Visione Artificiale"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
